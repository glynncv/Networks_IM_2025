{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Network Incident Analysis Pipeline\n",
        "\n",
        "This notebook processes network incident data and generates pipeline metrics for operational monitoring."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timezone\n",
        "import logging\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the ETL functions from the scripts module\n",
        "import sys\n",
        "sys.path.append('../scripts')\n",
        "\n",
        "try:\n",
        "    from network_incident_etl import transform_incident_frame, log_pipeline_metrics\n",
        "    print(\"‚úÖ Successfully imported ETL functions\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Import error: {e}\")\n",
        "    print(\"Make sure the network_incident_etl.py file exists in the scripts directory\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create sample data for testing\n",
        "sample_data = [\n",
        "    {\n",
        "        'opened_at': '2025-04-01T09:00:00Z',\n",
        "        'u_resolved': '2025-04-01T11:30:00Z',\n",
        "        'assignment_group': 'Network Operations',\n",
        "        'short_description': 'WiFi connection issues in building A',\n",
        "        'u_ci_type': 'WiFi/AP',\n",
        "        'priority': '2 - High',\n",
        "        'incident_state': 'Resolved'\n",
        "    },\n",
        "    {\n",
        "        'opened_at': '2025-04-02T14:00:00Z',\n",
        "        'u_resolved': '2025-04-02T16:45:00Z',\n",
        "        'assignment_group': 'Network Support',\n",
        "        'short_description': 'VPN tunnel down for remote users',\n",
        "        'u_ci_type': 'VPN',\n",
        "        'priority': '1 - Critical',\n",
        "        'incident_state': 'Resolved'\n",
        "    },\n",
        "    {\n",
        "        'opened_at': '2025-04-03T10:30:00Z',\n",
        "        'u_resolved': None,\n",
        "        'assignment_group': 'Network Operations',\n",
        "        'short_description': 'Switch port 5 down in data center',\n",
        "        'u_ci_type': 'Network Infrastructure',\n",
        "        'priority': '1 - Critical',\n",
        "        'incident_state': 'In Progress'\n",
        "    },\n",
        "    {\n",
        "        'opened_at': '2025-04-04T08:15:00Z',\n",
        "        'u_resolved': '2025-04-04T09:30:00Z',\n",
        "        'assignment_group': 'Application Support',\n",
        "        'short_description': 'DNS resolution slow for internal apps',\n",
        "        'u_ci_type': 'DNS',\n",
        "        'priority': '3 - Moderate',\n",
        "        'incident_state': 'Resolved'\n",
        "    },\n",
        "    {\n",
        "        'opened_at': '2025-04-05T11:00:00Z',\n",
        "        'u_resolved': '2025-04-05T12:15:00Z',\n",
        "        'assignment_group': 'Network Operations',\n",
        "        'short_description': 'Performance issues with ClearCase build system',\n",
        "        'u_ci_type': 'Application',\n",
        "        'priority': '2 - High',\n",
        "        'incident_state': 'Resolved'\n",
        "    }\n",
        "]\n",
        "\n",
        "# Create DataFrame\n",
        "raw_df = pd.DataFrame(sample_data)\n",
        "print(f\"‚úÖ Created sample dataset with {len(raw_df)} records\")\n",
        "print(\"\\nSample data preview:\")\n",
        "print(raw_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transform the incident data\n",
        "try:\n",
        "    tidy_df = transform_incident_frame(raw_df)\n",
        "    print(f\"‚úÖ Successfully transformed {len(tidy_df)} records\")\n",
        "    print(\"\\nTransformed data preview:\")\n",
        "    print(tidy_df[['short_description', 'patternCategory', 'resolutionTimeHrs', 'isActive', 'userImpactEstimate']].head())\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error during transformation: {e}\")\n",
        "    # Create a fallback DataFrame if transformation fails\n",
        "    tidy_df = raw_df.copy()\n",
        "    tidy_df['patternCategory'] = 'Other_Network'\n",
        "    tidy_df['resolutionTimeHrs'] = 0\n",
        "    tidy_df['isActive'] = False\n",
        "    tidy_df['userImpactEstimate'] = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up metrics logging with Windows-compatible path\n",
        "# Create a temporary file path that works on Windows\n",
        "temp_dir = tempfile.gettempdir()\n",
        "csv_fallback_path = os.path.join(temp_dir, 'ops_metrics.csv')\n",
        "\n",
        "print(f\"üìÅ Using fallback CSV path: {csv_fallback_path}\")\n",
        "\n",
        "# Log pipeline metrics (engine=None means we'll use CSV fallback)\n",
        "try:\n",
        "    log_pipeline_metrics(raw_df, tidy_df, engine=None, csv_fallback=csv_fallback_path)\n",
        "    print(\"‚úÖ Pipeline metrics logged successfully\")\n",
        "    \n",
        "    # Check if CSV file was created\n",
        "    if os.path.exists(csv_fallback_path):\n",
        "        print(f\"üìä Metrics saved to: {csv_fallback_path}\")\n",
        "        # Read and display the metrics\n",
        "        metrics_df = pd.read_csv(csv_fallback_path)\n",
        "        print(\"\\nPipeline Metrics:\")\n",
        "        print(metrics_df.to_string(index=False))\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  CSV file not created - metrics may have been logged to console only\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error logging metrics: {e}\")\n",
        "    print(\"Continuing without metrics logging...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display summary statistics\n",
        "print(\"üìä PIPELINE SUMMARY\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Raw records: {len(raw_df)}\")\n",
        "print(f\"Transformed records: {len(tidy_df)}\")\n",
        "print(f\"Active incidents: {tidy_df['isActive'].sum()}\")\n",
        "print(f\"High impact incidents: {tidy_df['isHighImpact'].sum()}\")\n",
        "\n",
        "if 'patternCategory' in tidy_df.columns:\n",
        "    print(\"\\nüìà Pattern Categories:\")\n",
        "    pattern_counts = tidy_df['patternCategory'].value_counts()\n",
        "    for pattern, count in pattern_counts.items():\n",
        "        print(f\"  {pattern}: {count}\")\n",
        "\n",
        "if 'resolutionTimeHrs' in tidy_df.columns:\n",
        "    resolved_incidents = tidy_df[tidy_df['resolutionTimeHrs'] > 0]\n",
        "    if len(resolved_incidents) > 0:\n",
        "        avg_resolution = resolved_incidents['resolutionTimeHrs'].mean()\n",
        "        print(f\"\\n‚è±Ô∏è  Average resolution time: {avg_resolution:.1f} hours\")\n",
        "\n",
        "print(\"\\n‚úÖ Pipeline execution complete!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}